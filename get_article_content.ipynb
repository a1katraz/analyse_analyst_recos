{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c1585c-fac3-4a2a-a15d-810321316290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas\n",
    "import base64\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from bs4 import BeautifulSoup \n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "import os\n",
    "import dotenv as env\n",
    "env.load_dotenv('../keys.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ed99834-ce9d-41fd-b813-bce026b0b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process the identified links to get their texts as a list of headline, subheader and body content\n",
    "def get_livemint_articles(art_url):\n",
    "    headline = ''\n",
    "    subhead = ''\n",
    "    body = ''\n",
    "    art_date = ''\n",
    "    \n",
    "    #art_url = top_headlines.iat[2, 1]\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119 Safari/537.36'\n",
    "    }\n",
    "    art_res = requests.get(art_url, headers=headers)\n",
    "    if(art_res.status_code == requests.codes.ok):\n",
    "        #Done\n",
    "        art_soup = BeautifulSoup(art_res.content, 'html.parser')\n",
    "        head_h1 = art_soup.find('h1', {'id':'article-0'})  #This might not be affected by changes in web page \n",
    "        if head_h1:\n",
    "            headline = head_h1.get_text()\n",
    "        else:\n",
    "            print(f'{art_url}: No headline found')\n",
    "            \n",
    "        sub_head_h2 = art_soup.find('h2', {'class':'storyPage_summary__Ge5SX'}) #This might fail on a daily basis, just switch to using h2 then \n",
    "        if sub_head_h2:\n",
    "            subhead = sub_head_h2.get_text() # Can be used to improve sharpness of LLM \n",
    "        else:\n",
    "            print(f'{art_url}: No subhead found')\n",
    "        \n",
    "        art_body_divs = art_soup.find_all('div', {'class': 'storyParagraph'}) # should work well and not fail\n",
    "        if art_body_divs:\n",
    "            for para_div in art_body_divs:\n",
    "                para = para_div.get_text()\n",
    "                if 'Disclaimer' not in para:   #reject boiler plate text to reduce tokens to LLMs\n",
    "                    if(body):\n",
    "                        body = body + '\\n' +  para\n",
    "                    else:\n",
    "                        body = para\n",
    "        else:\n",
    "            print(f'{art_url}: No Article Body found')\n",
    "            \n",
    "        art_date_div = art_soup.find('div', {'class': 'storyPage_date__JS9qJ storyPage_top__RFRL3'}) #find date\n",
    "        if art_date_div:\n",
    "            art_date = art_date_div.get_text()\n",
    "        else:\n",
    "            print(f'{art_url}: No article date found')\n",
    "        #print (body)\n",
    "        article_frame = pandas.DataFrame([[headline, subhead, body, art_date]], columns=['article_title', 'article_subheader', 'article_body', 'article_date'])\n",
    "        return article_frame\n",
    "    else:\n",
    "        print('Access to specific article' + art_url + 'is failing')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e12f5edc-5848-4b3b-8299-70a4255f3003",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommendations(BaseModel):\n",
    "    reco_date: str\n",
    "    analyst: str\n",
    "    house: str\n",
    "    stock_name: str\n",
    "    ticker: str\n",
    "    current_value: float\n",
    "    target_value: float\n",
    "    sl_value: float\n",
    "    timeframe: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf5e41-0b55-4dce-8ed8-338e67e4962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the article and making sense of it\n",
    "\n",
    "def get_value_table(article_frame):\n",
    "    client = genai.Client(\n",
    "            #api_key = GEMINI_API_KEY\n",
    "            api_key=os.environ.get(\"GEMINI_API_KEY\"),\n",
    "        )\n",
    "    \n",
    "    model = 'gemini-2.0-flash-lite'\n",
    "    #\"gemini-2.5-pro-exp-03-25\"\n",
    "    # see list here: https://ai.google.dev/gemini-api/docs/models#gemini-2.5-pro-preview-03-25\n",
    "    \n",
    "    generate_content_config = types.GenerateContentConfig(\n",
    "                                temperature=0.8,\n",
    "                                #response_mime_type=\"text/plain\", # for simpler use cases where only text is expected from the model \n",
    "                                system_instruction=[\n",
    "                                                    types.Part.from_text(text=\"\"\"You are a text analyser searching for explicit recommendations on a stock in an article.\n",
    "                                                    You are given data in a json format. The json format also names the fields of the data.\n",
    "                                                    Scan 'article_title' field in the json the name of individual stocks.\n",
    "                                                    You may also find the name of the stock analyst in 'article_title'.\n",
    "                                                    Scan 'article_subheader' field for the name of individual stocks.\n",
    "                                                    You may also find the name of the stock analyst and their brokerage house in the 'article_subheader'.\n",
    "                                                    You may also find the name of the stock analyst and their brokerage house in the 'article_body' field.\n",
    "                                                    There will also be an 'article_body' field .\n",
    "                                                    Reading through the contents of the article_title, article_subheader and article_body fields, conduct the following steps:\n",
    "                                                    \n",
    "                                                    1. Identify the stock names being recommended in the three fields. These names will be explicity mentioned.\n",
    "                                                    Ignore names and values of indices like NIFTY, BANKNIFTY, NIFTY REALTY, SENSEX, Dow Jones, S&P 500, NASDQ, NYSE, HANGSENG.\n",
    "                                                    Only collect individual stock names explicity named in the article\n",
    "                                                    \n",
    "                                                    2. Identify the existing price or recommended buying price of the stock as given in these three fields. It may be present as a single value, or as a range (such as 100-125).\n",
    "                                                    It may also not be present in the article. Use only explicity mentioned values. Convert the range to its mid point. Take -1.0 as the value if not mentioned.\n",
    "                                                    \n",
    "                                                    3. Identify the target price of the stock. It may be a single value or a range or multiple values. It will be marked by the words *Target Price* or *Target*.\n",
    "                                                    Use only explicity mentioned values. Convert a range to its lower value. If there are multple targets, take the highest target. Take -1.0 as the value if not mentioned.\n",
    "                                                    \n",
    "                                                    4. Identify the stoploss price of the trade. It may be a single value or a range. It will be marked by the words *Stoploss* or *Stop Loss* or *Exit*.\n",
    "                                                    Use only explicity mentioned values. convert a range to its upper value. Take -1.0 as the value if not mentioned.\n",
    "                                                    \n",
    "                                                    5. Identify the ticker name of the stock identified in 1. Use your inherent knowledge of NSE ticker names if the stock ticker is not explicitly mentioned.\n",
    "                                                    If you cannot identify the ticker name, say None.\n",
    "                                                    \n",
    "                                                    6. Identify any timeframe mentioned for these recommendations. These timeframes can be a month, a week, or a quarter. If no timeframe is mentioned, say None. \n",
    "                                                    \n",
    "                                                    Finally, take the date from the 'article_date' field of the input json and convert it into yyyy-mm-dd format. If this field does not exist, use 'Not Found' as the date.\n",
    "                                                    \n",
    "                                                    Return your response in the form of article date, analyst name, brokerage house, stock name, NSE ticker, buy price, target price, stoploss price and timeframe\n",
    "                                                    for each of the stock name mentioned in the article.\n",
    "                                                    \"\"\"),\n",
    "                                            ],\n",
    "                                response_mime_type='application/json',\n",
    "                                response_schema=list[Recommendations],    #force response in a structured format from Gemini\n",
    "                                )\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                #types.Part.from_text(text=\"|\".join(article_body)),  #this part has to be fixed to send a json list of strings to the model. Otherwise cheaper models can mix up the sentence and the delimiter and miss some sentences.  \n",
    "                types.Part.from_text(text=article_frame.to_json(orient=\"records\"))\n",
    "                ],\n",
    "            ),\n",
    "        ]\n",
    "    \n",
    "    model_reply = client.models.generate_content(model=model, contents=contents, config=generate_content_config)\n",
    "    return model_reply.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aedbf880-e781-4a67-a0d9-01ae79ac62ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One line testing\n",
    "\n",
    "#out = get_livemint_articles('https://www.livemint.com/market/stock-market-news/stocks-to-buy-or-sell-dharmesh-shah-of-icici-securities-suggests-buying-ultratech-cement-hal-shares-on-21-april-2025-11745088225280.html')\n",
    "#print(out)\n",
    "#out_df = pandas.DataFrame([out], columns=['article_title', 'article_subheader', 'article_body', 'article_date'])\n",
    "#results = get_value_table(out)\n",
    "#print(json.loads(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
