{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe1f055-4430-4d0f-aa6a-0f04ae44621d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "import requests\n",
    "import pandas\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "import random\n",
    "import pprint as pp\n",
    "import dotenv as env\n",
    "env.load_dotenv('../keys.env')\n",
    "\n",
    "#<script async src=\"https://cse.google.com/cse.js?cx=314b1cf0785af4af3\">\n",
    "#</script>\n",
    "#<div class=\"gcse-search\"></div>\n",
    "\n",
    "#API Doc here: https://developers.google.com/custom-search/v1/reference/rest/v1/cse/list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "628ff761-52ca-4520-8b8f-f83264dea36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class google_Search:\n",
    "    __SEARCH_API_KEY = os.environ.get('SEARCH_API_KEY')\n",
    "    __cx_id = os.environ.get('SEARCH_CX_ID')\n",
    "    \n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def __sanitize_query(self, query):\n",
    "        query = query.strip()\n",
    "        sanitized_query = urllib.parse.quote_plus(query)\n",
    "        return sanitized_query\n",
    "    \n",
    "    def search(self, query, terms='None', num_pages=1, silent_mode=True) -> pandas.DataFrame:\n",
    "        if(silent_mode):\n",
    "            original_stdout = sys.stdout   # save the original stdout\n",
    "            sys.stdout = open(os.devnull, 'w')\n",
    "        uuids = []\n",
    "        headlines = []\n",
    "        links = []\n",
    "        link_id = []\n",
    "        max_page = 10   #max pages to which we can run custom search\n",
    "        if(query!=''):\n",
    "            query = self.__sanitize_query(query)\n",
    "            cur_page = 0\n",
    "            while cur_page < num_pages and cur_page < max_page :\n",
    "                url = f'https://www.googleapis.com/customsearch/v1?key={google_Search.__SEARCH_API_KEY}&cx={google_Search.__cx_id}&q={query}&exact={terms}&num=10&start={cur_page*10+1}'\n",
    "                print(f'Running search for {query} on page: {cur_page+1}')\n",
    "                response = requests.get(url)\n",
    "                if(response.status_code == 200):\n",
    "                    data = response.json()\n",
    "                    print(f'Found {len(data['items'])} on page {cur_page+1}')\n",
    "                    for item in data['items']:\n",
    "                        uuids.append(uuid.UUID(int=random.getrandbits(128), version=4))\n",
    "                        headlines.append(item['pagemap']['metatags'][0]['og:description']) #index called 'og:description  has a name of the link'\n",
    "                        links.append(item['link'])\n",
    "                        link_id.append(item['link'][-19:][:14])\n",
    "                else:\n",
    "                    print(f'Error: {response.status_code} at run page: {cur_page+1}')\n",
    "                    break\n",
    "                cur_page += 1 \n",
    "            print('Combining all outcomes...')\n",
    "            search_headlines = pandas.DataFrame({\n",
    "                                    'uuid': uuids, \n",
    "                                    'title': headlines,     #Don't change these column names, they are important for merging later \n",
    "                                    'link': links,\n",
    "                                    'link_id': link_id\n",
    "                                    })\n",
    "            search_headlines.insert(1, 'site', 'Livemint')  #Because currently our search engine is set to search on LiveMint.\n",
    "            \n",
    "            print('Deduping links...')\n",
    "            search_headlines.drop_duplicates(subset=['link_id'], keep='first', inplace=True, ignore_index=True)\n",
    "            if(silent_mode):\n",
    "                sys.stdout.close()\n",
    "                sys.stdout = original_stdout    #restore the original stdout, other wise it will fail other prints.\n",
    "            return search_headlines\n",
    "        else:\n",
    "            if(silent_mode):\n",
    "                sys.stdout.close()\n",
    "                sys.stdout = original_stdout\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454e62d8-bc53-43f9-81a5-869382e2a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one line tester\n",
    "\n",
    "#search_engine = google_Search()\n",
    "#links = search_engine.search(query='Sumeet Bagadia', terms='Buy', num_pages=1, silent_mode=True)\n",
    "#pp.pprint(links)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
