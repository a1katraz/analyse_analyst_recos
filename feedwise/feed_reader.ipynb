{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0bd4571-fd21-4045-bd7d-e75ffabb5481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb.fs.full.dict_maker as dictionary\n",
    "import requests\n",
    "import feedparser\n",
    "import pandas \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39449079-7499-4e78-b015-f82966cbc5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class livemint_reader:\n",
    "    \n",
    "    @staticmethod\n",
    "    def read_feed(url:str) -> pandas.DataFrame:\n",
    "        try:\n",
    "            print(f'Reading feed from {url} for Livemint...')\n",
    "            feed = feedparser.parse(url)\n",
    "            titles = []\n",
    "            links = []\n",
    "            link_ids = []\n",
    "            article_dates = []\n",
    "            article_summaries = []\n",
    "            \n",
    "            for entry in feed.entries:\n",
    "                titles.append(entry.title)\n",
    "                links.append(entry.link)\n",
    "                link_ids.append(entry.link[-19:][:14])\n",
    "                article_dates.append(datetime.strptime(entry.published[5:], '%d %b %Y %H:%M:%S %z'))\n",
    "                article_summaries.append(entry.summary)\n",
    "\n",
    "            df = pandas.DataFrame(\n",
    "                    data={\n",
    "                        'title': titles,\n",
    "                        'link': links,\n",
    "                        'link_id': link_ids,\n",
    "                        'link_date': article_dates,\n",
    "                        'link_summary': article_summaries\n",
    "                    }\n",
    "                )\n",
    "            if(not df.empty):          #feed can be empty sometimes\n",
    "                df.insert(0, 'site_name', 'Livemint')\n",
    "            return df\n",
    "        \n",
    "        except feedparser.ExpatError as e:\n",
    "            print(f\"XML parsing error: {e}\")\n",
    "        except feedparser.NotFeedException as e:\n",
    "            print(f\"Not a valid feed: {e}\")\n",
    "        except feedparser.CharacterEncodingUnknown as e:\n",
    "            print(f\"Unknown character encoding error: {e}\")\n",
    "        except feedparser.ParseError as e:\n",
    "            print(f\"Parse error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f685b41-389f-42a0-86fa-cca99036bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tradebrains_reader:\n",
    "\n",
    "    @staticmethod\n",
    "    def read_feed(url:str) -> pandas.DataFrame:\n",
    "        try:\n",
    "            print(f'Reading feed from {url} Tradebrains...')\n",
    "            feed = feedparser.parse(url)\n",
    "            titles = []\n",
    "            links = []\n",
    "            link_ids = []\n",
    "            article_dates = []\n",
    "            article_summaries = []\n",
    "            \n",
    "            for entry in feed.entries:\n",
    "                titles.append(entry.title)\n",
    "                links.append(entry.link)\n",
    "                link_ids.append(entry.guid[-5:])\n",
    "                article_dates.append(datetime.strptime(entry.published[5:], '%d %b %Y %H:%M:%S %z'))\n",
    "                article_summaries.append(entry.summary[:1000])           #Could be very long, so have shortened to 1000 chars to fit in the db \n",
    "\n",
    "            df = pandas.DataFrame(\n",
    "                    data={\n",
    "                        'title': titles,\n",
    "                        'link': links,\n",
    "                        'link_id': link_ids,\n",
    "                        'link_date': article_dates,\n",
    "                        'link_summary': article_summaries\n",
    "                    }\n",
    "                )\n",
    "            \n",
    "            if(not df.empty):          #feed can be empty sometimes\n",
    "                df.insert(0, 'site_name', 'Tradebrains')\n",
    "            return df\n",
    "        \n",
    "        except feedparser.ExpatError as e:\n",
    "            print(f\"XML parsing error: {e}\")\n",
    "        except feedparser.NotFeedException as e:\n",
    "            print(f\"Not a valid feed: {e}\")\n",
    "        except feedparser.CharacterEncodingUnknown as e:\n",
    "            print(f\"Unknown character encoding error: {e}\")\n",
    "        except feedparser.ParseError as e:\n",
    "            print(f\"Parse error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9078e993-296d-4359-8349-f8d675ad1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class economic_times_reader:\n",
    "\n",
    "    @staticmethod\n",
    "    def read_feed(url:str) -> pandas.DataFrame:\n",
    "        try:\n",
    "            print(f'Reading feed from {url} Economic Times...')\n",
    "            feed = feedparser.parse(url)\n",
    "            titles = []\n",
    "            links = []\n",
    "            link_ids = []\n",
    "            article_dates = []\n",
    "            article_summaries = []\n",
    "\n",
    "            if (url == 'https://economictimes.indiatimes.com/rsssymbolfeeds/commodityname-Gold.cms'): #spl case for Gold RSS on ET because of timeframe type\n",
    "                time_format =  '%Y-%m-%dT%H:%M:%S%z'\n",
    "                start_idx = 0\n",
    "            else:\n",
    "                time_format = '%d %b %Y %H:%M:%S %z'\n",
    "                start_idx = 5\n",
    "            \n",
    "            for entry in feed.entries:\n",
    "                titles.append(entry.title)\n",
    "                links.append(entry.link)\n",
    "                link_ids.append(entry.guid[-13:][:9]) if ('guid' in entry) else link_ids.append('None')                                 #May not exist, hence the case\n",
    "                article_dates.append(datetime.strptime(entry.published[start_idx:], time_format))  if ('published' in entry) else article_dates.append(datetime.date.today())   #May not exist, hence the case\n",
    "                article_summaries.append(entry.summary[:1022]) if('summary' in entry) else article_summaries.append('None')      #Could be very long, so have shortened to 1000 chars to fit in the db. May not even exist\n",
    "\n",
    "            df = pandas.DataFrame(\n",
    "                    data={\n",
    "                        'title': titles,\n",
    "                        'link': links,\n",
    "                        'link_id': link_ids,\n",
    "                        'link_date': article_dates,\n",
    "                        'link_summary': article_summaries\n",
    "                    }\n",
    "                )\n",
    "            if(not df.empty):          #feed can be empty sometimes\n",
    "                df.insert(0, 'site_name', 'Economic Times')\n",
    "            return df\n",
    "        \n",
    "        except feedparser.ExpatError as e:\n",
    "            print(f\"XML parsing error: {e}\")\n",
    "        except feedparser.NotFeedException as e:\n",
    "            print(f\"Not a valid feed: {e}\")\n",
    "        except feedparser.CharacterEncodingUnknown as e:\n",
    "            print(f\"Unknown character encoding error: {e}\")\n",
    "        except feedparser.ParseError as e:\n",
    "            print(f\"Parse error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e1bdc5c-2e68-4000-9102-e5482076954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hindubusinessline_times_reader:\n",
    "\n",
    "    @staticmethod\n",
    "    def read_feed(url:str) -> pandas.DataFrame:\n",
    "        try:\n",
    "            print(f'Reading feed from {url} Hindu Business Line...')\n",
    "            feed = feedparser.parse(url)\n",
    "            titles = []\n",
    "            links = []\n",
    "            link_ids = []\n",
    "            article_dates = []\n",
    "            article_summaries = []\n",
    "\n",
    "            time_format = '%d %b %Y %H:%M:%S %z'\n",
    "            \n",
    "            for entry in feed.entries:\n",
    "                titles.append(entry.title)\n",
    "                links.append(entry.link)\n",
    "                link_ids.append(entry.guid) if ('guid' in entry) else link_ids.append('None')                                 #May not exist, hence the case\n",
    "                article_dates.append(datetime.strptime(entry.published[5:], time_format))  if ('published' in entry) else article_dates.append(datetime.date.today())   #May not exist, hence the case\n",
    "                article_summaries.append(entry.summary[:1022]) if('summary' in entry) else article_summaries.append('None')      #Could be very long, so have shortened to 1000 chars to fit in the db. May not even exist\n",
    "\n",
    "            df = pandas.DataFrame(\n",
    "                    data={\n",
    "                        'title': titles,\n",
    "                        'link': links,\n",
    "                        'link_id': link_ids,\n",
    "                        'link_date': article_dates,\n",
    "                        'link_summary': article_summaries\n",
    "                    }\n",
    "                )\n",
    "            if(not df.empty):          #feed can be empty sometimes\n",
    "                df.insert(0, 'site_name', 'Hindu Business Line')\n",
    "            return df\n",
    "        \n",
    "        except feedparser.ExpatError as e:\n",
    "            print(f\"XML parsing error: {e}\")\n",
    "        except feedparser.NotFeedException as e:\n",
    "            print(f\"Not a valid feed: {e}\")\n",
    "        except feedparser.CharacterEncodingUnknown as e:\n",
    "            print(f\"Unknown character encoding error: {e}\")\n",
    "        except feedparser.ParseError as e:\n",
    "            print(f\"Parse error: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5bc3245-1aef-4df4-8c92-17edadc67613",
   "metadata": {},
   "outputs": [],
   "source": [
    "class feed_reader(livemint_reader, tradebrains_reader, economic_times_reader, hindubusinessline_times_reader):\n",
    "    @classmethod\n",
    "    def read_feed(cls, site: str, url: str) -> pandas.DataFrame:\n",
    "        if(site == 'Livemint'):\n",
    "            return livemint_reader.read_feed(url)\n",
    "        elif(site == 'Tradebrains'):\n",
    "            return tradebrains_reader.read_feed(url)\n",
    "        elif(site == 'Economic Times'):\n",
    "            return economic_times_reader.read_feed(url)\n",
    "        elif(site == 'Hindu Business Line'):\n",
    "            return hindubusinessline_times_reader.read_feed(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6225904f-56ec-4640-ad6d-aa351c71baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One line tester\n",
    "#url = dictionary.dict_to_json.get_value_from_file('Markets')\n",
    "#df = livemint_reader.read_feed(url)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d152e2-cb79-4f3b-aa0d-f4309d02cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obj = datetime.strptime('19 May 2025 11:53:01 +0530', '%d %B %Y %H:%M:%S %z')\n",
    "#print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ffc752e-6b00-42af-992e-07cc2461a965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One line tester\n",
    "#url = dictionary.dict_to_json.get_value_from_file('Markets')\n",
    "#df = tradebrains_reader.read_feed('https://tradebrains.in/feed/')\n",
    "#for idx, row in df.iterrows():\n",
    "#    print(len(row['link_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "799587cd-4ff0-4a08-8e86-db6b6c70f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One line tester\n",
    "#url = dictionary.dict_to_json.get_value_from_file('Economic Times', 'Markets')\n",
    "#df = economic_times_reader.read_feed(url)\n",
    "#df.head()\n",
    "#for idx, row in df.iterrows():\n",
    "#    print(len(row['link_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4f68dd0-41aa-4a43-8b18-ada4387d5524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One line tester\n",
    "#url = dictionary.dict_to_json.get_value_from_file('Hindu Business Line', 'Top Gainers/Top Losers')\n",
    "#df = hindubusinessline_times_reader.read_feed(url)\n",
    "#df.head()\n",
    "#for idx, row in df.iterrows():\n",
    "#    print(row['link_summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb061fd-eb2e-4399-8656-4385f1af653e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
