{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67e4d08b-1229-4684-9052-eacab80e0aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import ipynb.fs.full.data_operations as do\n",
    "import ipynb.fs.full.feed_reader as fr\n",
    "import ipynb.fs.full.dict_maker as dictionary\n",
    "import ipynb.fs.full.backtester as bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f31bd3f-6745-49e7-88c6-ca22ae01c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class main:\n",
    "    @staticmethod\n",
    "    def insert_prev_recos_in_table():\n",
    "        recos = pandas.read_csv('../../data/prev_recos.csv', sep=',', na_values=['None'])\n",
    "        recos['reco_date'] = pandas.to_datetime(recos['reco_date']).dt.strftime('%Y-%m-%d')\n",
    "        recos.replace('None', None, inplace=True)\n",
    "        #print(recos.head)\n",
    "        db = do.mysql_Database('analyst_feeds')\n",
    "        db.insert_values_in_table('reco_repository', recos)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_article_links(site_links: dict):\n",
    "        db = do.mysql_Database('analyst_feeds')                                            #Initialize the MySQL DB\n",
    "\n",
    "        for site, value in site_links.items():          \n",
    "            for idx, sub_site in enumerate(value):\n",
    "                url = dictionary.dict_to_json.get_value_from_file(site, sub_site)        #Get the url for this sub-site for this site\n",
    "                #print(f'{site} - {sub_site} - {url}')\n",
    "                feeder = fr.feed_reader.read_feed(site, url)                          #Get all the links for feed for this sub-site as a DataFrame\n",
    "                \n",
    "                if(not feeder.empty):                                #sometimes feeds can also be empty\n",
    "                    feeder.insert(1, 'sub_site_name', sub_site)\n",
    "                    print(f'Found {feeder.shape[0]} links. Now deduping...')\n",
    "                    links_seen = db.search_values_in_table('feeds_seen', 'link_id', feeder['link_id'], ['site_name', 'sub_site_name'], [site, sub_site], ['link_id'])       #Get values which are already in the table\n",
    "                    print(f'Found {links_seen.shape[0]} links which have been analysed before...')\n",
    "                    links_to_add = feeder[~feeder['link_id'].isin(links_seen['link_id'])]                    #remove values already in the table\n",
    "                    if(not links_to_add.empty):   #if there are links worth adding. Writing an empty df to the table with replace clause will cause it to delete all other values  \n",
    "                        print(f'Inserting {links_to_add.shape[0]} new links to the table...')\n",
    "                        db.insert_values_in_table('feeds_seen', links_to_add[['link_id', 'site_name', 'sub_site_name', 'link', 'link_date', 'title', 'link_summary']])                                         #Insert table values of links seen so as to not repeat\n",
    "                else:\n",
    "                    print(f'No feed found for {site} - {sub_site} today. ')\n",
    "                \n",
    "        db.extinguish_connection()\n",
    "        print('DB connection closed. Exiting...')\n",
    "\n",
    "    @staticmethod\n",
    "    def one_time_db_cleanup(filename:str):\n",
    "        df = pandas.read_csv(filename, sep=',',header=0)\n",
    "        db = do.mysql_Database('analyst_feeds')                                            #Initialize the MySQL DB\n",
    "        db.update_a_table_column(df)  \n",
    "\n",
    "    @staticmethod\n",
    "    def run_backtests_on_all_recos(analyst:str):\n",
    "        db = do.mysql_Database('analyst_feeds')\n",
    "        recos = db.search_values_in_table(tablename='reco_repository', test_field='analyst', match_values=pandas.Series(analyst), aux_fields=['site_name'], aux_field_values=['Livemint'])\n",
    "        \n",
    "        for idx, row in recos.iterrows():\n",
    "            try:\n",
    "                tester = bt.ticker_Data(ticker=row['ticker'], start_date=row['reco_date'].strftime('%Y-%m-%d'), in_price=row['reco_value'], tgt_price=row['tgt_value'], sl_price=row['sl_value'])\n",
    "                if(tester.sanity_test(row)):\n",
    "                    price_data = tester.get_price_data()\n",
    "                    tester.simple_win_or_loss(price_data)\n",
    "                    insert_df = pandas.DataFrame(\n",
    "                            data={\n",
    "                                'reco_id': [row['reco_id']],\n",
    "                                'ticker': [row['ticker']],\n",
    "                                'testable': [1],\n",
    "                                'outcome': [json.dumps(tester.outcome)],\n",
    "                                'result': [tester.outcome.get('result')],\n",
    "                                'result_price': [tester.outcome_price],\n",
    "                                'result_horizon': [tester.return_horizon],\n",
    "                                'result_return': [tester.return_rate]\n",
    "                            }\n",
    "                        )\n",
    "                    db.insert_values_in_table(tablename='reco_backtest_results', df=insert_df)\n",
    "                else:\n",
    "                    #print(f'Sanity test for row {idx} for ticker {tester.ticker} at start_date {tester.start_date} is False')\n",
    "                    insert_df = pandas.DataFrame(\n",
    "                            data={\n",
    "                                'reco_id': [row['reco_id']],\n",
    "                                'ticker': [row['ticker']],\n",
    "                                'testable': [0]\n",
    "                            }\n",
    "                        )\n",
    "                    db.insert_values_in_table(tablename='reco_backtest_results', df=insert_df)\n",
    "            except Exception as e:\n",
    "                print(f'Caught exception {e} in processing row {idx} with reco_id {row['reco_id']}.')\n",
    "                insert_df = pandas.DataFrame(\n",
    "                            data={\n",
    "                                'reco_id': [row['reco_id']],\n",
    "                                'ticker': [row['ticker']],\n",
    "                                'testable': [1],\n",
    "                                'result': ['failure'],\n",
    "                            }\n",
    "                        )\n",
    "                db.insert_values_in_table(tablename='reco_backtest_results', df=insert_df)\n",
    "            finally:\n",
    "                continue\n",
    "\n",
    "    #@staticmethod\n",
    "    #def get_google_links\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647f601e-5de8-4ba7-9077-d32b3865d26e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
