{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a3c2531-eb4f-4563-b08e-925e242b9d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb.fs.full.get_news_headlines as gethl\n",
    "import ipynb.fs.full.get_article_content as getart\n",
    "import ipynb.fs.full.write_data as gswd\n",
    "import pandas\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49dc1f99-b242-4ec4-9121-76474ae03534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        hl = gethl.read_livemint_headlines()  #Get headlines\n",
    "        #outcomes = pandas.DataFrame()\n",
    "        \n",
    "        if(not(hl.empty)):\n",
    "            \n",
    "            classified_hl = pandas.DataFrame(json.loads(gethl.classify_headlines(hl['title'].tolist())))  # converting to json the model reply from Gemini AI.\n",
    "            classified_titles = hl.join(classified_hl, lsuffix='_orig', rsuffix='_copy')   #make one df given with surety that matching is happening on indexes because Title matching used to give missed matches.. \n",
    "            classified_titles = classified_titles[classified_titles.classification]  #keeping only the titles with a analyst recommerndation here.\n",
    "            classified_titles.drop_duplicates(subset=['link_id'], keep='first', inplace=True, ignore_index=False)        #remove duplicates that can creep in from multiple uls   \n",
    "            gswd.write_headlines(classified_titles)  #write titles to a google file\n",
    "\n",
    "            for idx, row in classified_titles.iterrows():\n",
    "                article = getart.get_livemint_articles(row['link'])   #read each article and get it title, subheader, body, and date\n",
    "                table = getart.get_value_table(article)               # send it to to LLM to make sense of it \n",
    "                value_table = pandas.DataFrame(json.loads(table))      # Store the outcomes\n",
    "                if(not(value_table.empty)):\n",
    "                    value_table.insert(0, 'uuid', str(row['uuid']))    # This UUID object is not serializable so better we convert it to string here\n",
    "                    #value_table.insert(1, 'link', row['link'])        #Just having the UUID should solve the problem  now.\n",
    "                    #value_table.insert(2, 'site', 'Livemint')\n",
    "                    #print(value_table)\n",
    "                    gswd.write_recommendations(value_table)\n",
    "                else:\n",
    "                    print(f'No recommendations received for article: {row['link']}')\n",
    "                \n",
    "        else:\n",
    "            print('No Headlines Received')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fce2d12-bffe-4cb0-a473-a63f4dc6e38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    hl = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58199546-fe8e-4ce2-8d0e-e565052d28a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
